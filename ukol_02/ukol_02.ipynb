{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import SCORERS, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "pd.set_option(\"display.max_columns\", 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load + preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Root MSE function\n",
    "def rmse(x, y):\n",
    "    return sqrt(mean_squared_error(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset into a Pandas dataframe\n",
    "df = pd.read_csv('data/attrition.csv')\n",
    "\n",
    "# drop columns with \n",
    "df.drop(['EmployeeNumber', 'Attrition', 'Over18', 'StandardHours', 'EmployeeCount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make it some fun\n",
    "df.drop('JobLevel', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select response variable and features\n",
    "target_col_name = 'MonthlyIncome'\n",
    "num_feature_cols = [\n",
    "        'Age', 'DailyRate','DistanceFromHome', 'Education',\n",
    "        'HourlyRate', 'EnvironmentSatisfaction', 'JobInvolvement',\n",
    "        'JobSatisfaction', 'NumCompaniesWorked', 'PercentSalaryHike',\n",
    "        'RelationshipSatisfaction', 'StockOptionLevel', 'PerformanceRating',\n",
    "        'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "        'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "        'YearsWithCurrManager', 'MonthlyRate']\n",
    "cat_feature_cols = [x for x in df.columns if x not in num_feature_cols and x not in [target_col_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast numerical columns as float\n",
    "for col in num_feature_cols:\n",
    "    df[col] = df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target array and numeric features dataframe\n",
    "df_target = np.ravel(df[[target_col_name]])\n",
    "df_features = df[num_feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target array and features dataframe\n",
    "df_target = np.ravel(df[[target_col_name]])\n",
    "df_features_all = df[num_feature_cols + cat_feature_cols]\n",
    "\n",
    "# split the dataframe to train and test parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features_all, df_target, test_size=0.3, random_state=666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best performing regressors (based on $R^2$ and MSE) from class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transformer = Pipeline(steps=[\n",
    "                  ('imputer', SimpleImputer(strategy='median')),\n",
    "                  ('scaler', RobustScaler())])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "                  ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                  ('onehot', OneHotEncoder(categories='auto', \n",
    "                                     sparse=False, \n",
    "                                     handle_unknown='ignore'))])\n",
    "\n",
    "pipeline_preprocess = ColumnTransformer(transformers=[\n",
    "        ('numerical_preprocessing', num_transformer, num_feature_cols),\n",
    "        ('categorical_preprocessing', cat_transformer, cat_feature_cols)],\n",
    "        remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuned ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mse: 1683.6212040893834 \n",
      "\n",
      "Model mae: 1333.1106306639845 \n",
      "\n",
      "Model R2: 0.8686077406910069 \n",
      "\n",
      "Model coefs: [-113, 31, 0, -82, -16, 16, -65, 81, 28, 58, 103, 0, -269, 1802, -14, 0, 181, -66, 168, -292, -136, 0, 0, 0, 0, 381, 0, 0, 0, 0, -93, 0, 0, -65, 0, 0, -1297, -2852, 7648, 110, 6787, -2923, 408, -2451, -76, 0, 0, -6, 0] \n",
      "\n",
      "Model hyper_params: {'reg__alpha': 10, 'reg__l1_ratio': 1}\n"
     ]
    }
   ],
   "source": [
    "pipe0 = Pipeline([(\"transform_inputs\", pipeline_preprocess), (\"reg\", ElasticNet())])\n",
    "\n",
    "param_grid = {'reg__l1_ratio': [.1, .5, .7, .9, .95, 1], 'reg__alpha':[0.2, 0.5, 1, 4, 10, 20, 40, 100]}\n",
    "m4 = GridSearchCV(estimator=pipe0, param_grid=param_grid, cv=5, scoring='r2', iid=False).fit(X_train, y_train)\n",
    "\n",
    "m4_mse = rmse(m4.predict(X_test), y_test)\n",
    "m4_mae = mean_absolute_error(m4.predict(X_test), y_test)\n",
    "m4_r2 = m4.best_estimator_.score(X_test, y_test)\n",
    "\n",
    "print(f\"Model mse: {m4_mse} \\n\")\n",
    "print(f\"Model mae: {m4_mae} \\n\")\n",
    "print(f\"Model R2: {m4_r2} \\n\")\n",
    "print(f\"Model coefs: {[int(x) for x in m4.best_estimator_.named_steps['reg'].coef_]} \\n\")\n",
    "print(f\"Model hyper_params: {m4.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble models - Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mse: 1611.7270100233652 \n",
      "\n",
      "Model mae: 1232.3738221746291 \n",
      "\n",
      "Model R2: 0.8795896066643341 \n",
      "\n",
      "Model hyper_params: {'reg__max_depth': 10, 'reg__max_features': 'auto', 'reg__n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "pipe2 = Pipeline([(\"transform_inputs\", pipeline_preprocess), (\"reg\", RandomForestRegressor())])\n",
    "\n",
    "param_grid = {'reg__max_depth': [5, 10, 15], 'reg__n_estimators':[40, 100, 150], 'reg__max_features':['auto', 'sqrt']}\n",
    "m6 = GridSearchCV(estimator=pipe2, param_grid=param_grid, cv=5, scoring='r2', iid=False).fit(X_train, y_train)\n",
    "\n",
    "m6_mse = rmse(m6.predict(X_test), y_test)\n",
    "m6_mae = mean_absolute_error(m6.predict(X_test), y_test)\n",
    "m6_r2 = m6.best_estimator_.score(X_test, y_test)\n",
    "\n",
    "print(f\"Model mse: {m6_mse} \\n\")\n",
    "print(f\"Model mae: {m6_mae} \\n\")\n",
    "print(f\"Model R2: {m6_r2} \\n\")\n",
    "print(f\"Model hyper_params: {m6.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble models - Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mse: 1679.1742128032363 \n",
      "\n",
      "Model mae: 1302.094636683161 \n",
      "\n",
      "Model R2: 0.8693009234179803 \n",
      "\n",
      "Model hyper_params: {'reg__max_features': 'auto', 'reg__min_samples_leaf': 0.005, 'reg__n_estimators': 50, 'reg__subsample': 0.4}\n"
     ]
    }
   ],
   "source": [
    "pipe3 = Pipeline([(\"transform_inputs\", pipeline_preprocess), (\"reg\", GradientBoostingRegressor())])\n",
    "\n",
    "param_grid = {'reg__max_features': ['auto', 'sqrt'], 'reg__subsample': [0.1, 0.05, 0.4], 'reg__min_samples_leaf': [0.0025, 0.005, 0.01, 0.05, 0.1], 'reg__n_estimators':[30, 40, 50, 70, 200]}\n",
    "m7 = GridSearchCV(estimator=pipe3, param_grid=param_grid, cv=5, scoring='r2', iid=False).fit(X_train, y_train)\n",
    "\n",
    "m7_mse = rmse(m7.predict(X_test), y_test)\n",
    "m7_mae = mean_absolute_error(m7.predict(X_test), y_test)\n",
    "m7_r2 = m7.best_estimator_.score(X_test, y_test)\n",
    "\n",
    "print(f\"Model mse: {m7_mse} \\n\")\n",
    "print(f\"Model mae: {m7_mae} \\n\")\n",
    "print(f\"Model R2: {m7_r2} \\n\")\n",
    "print(f\"Model hyper_params: {m7.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR QUEST: Get better R2 and MSE then this ^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original param_grid\n",
    "param_grid = {'reg__max_depth': [3, 5, 10], \n",
    "              'reg__n_estimators': [50, 55, 60],\n",
    "              'reg__reg_alpha': [0.1, 0.2, 0.3],\n",
    "              'reg__reg_lambda': [0.1, 0.2, 0.3],\n",
    "             }\n",
    "#tried even more extreme values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosen hyperparameters: `max_depth = 3`, `n_estimators = 50`, `reg_alpha = 0.1`, `reg_lambda = 0.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe01 = Pipeline([(\"transform_inputs\", pipeline_preprocess), (\"reg\", XGBRegressor(objective ='reg:squarederror'))])\n",
    "\n",
    "param_grid = {'reg__max_depth': [3], \n",
    "              'reg__n_estimators': [50],\n",
    "              'reg__reg_alpha': [0.1],\n",
    "              'reg__reg_lambda': [0.2],\n",
    "             }\n",
    "m01 = GridSearchCV(estimator=pipe01, param_grid=param_grid, cv=5, scoring='r2', iid=False).fit(X_train, y_train)\n",
    "\n",
    "m01_mse = rmse(m01.predict(X_test), y_test)\n",
    "m01_mae = mean_absolute_error(m01.predict(X_test), y_test)\n",
    "m01_r2 = m01.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mse: 1551.8630327365893 \n",
      "\n",
      "Model mae: 1194.3279102005386 \n",
      "\n",
      "Model R2: 0.8883682372600944 \n",
      "\n",
      "Model hyper_params: {'reg__max_depth': 3, 'reg__n_estimators': 50, 'reg__reg_alpha': 0.1, 'reg__reg_lambda': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model mse: {m01_mse} \\n\")\n",
    "print(f\"Model mae: {m01_mae} \\n\")\n",
    "print(f\"Model R2: {m01_r2} \\n\")\n",
    "print(f\"Model hyper_params: {m01.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost does not perform that well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
